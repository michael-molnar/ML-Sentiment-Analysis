{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AIDI 1002 - AI Algorithms - Final Project\n",
    "\n",
    "### Sentiment Analysis\n",
    "\n",
    "Michael Molnar - Durham College #100806823\n",
    "\n",
    "## Notebook 3:  Model Preparation, Testing, and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem Statement:\n",
    "\n",
    "How can we use machine learning to automatically extract the sentiment of every review, comment, blog post, or news article that mentions your business or your products?  \n",
    "\n",
    "This project will create a model that will automatically analyze text and predict its sentiment - negative, neutral, or positive.  This solution will allow a business to automatically parse reviews and comments it receives, sorting them, and allowing for the analyis of how customers feel about the business and brand.  This analysis will allow for a company to determine how feelings towards the company change over time, or after the release of a new product or a shift in direction.  Unhappy customers can be automatically identified and prioritized.  \n",
    "\n",
    "The proposed solution will be a classification model trained on real product reviews to identify the key words and phrases that most accurately predict the sentiment of a sample of text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Focus of Notebook 3:\n",
    "\n",
    "In this notebook I will focus on algorithm testing.  I will first split the cleaned data into training and testing.  Then, I will downsample the majority class to evenly distribute the targets in the training data.  \n",
    "\n",
    "Next I will chose an evaluation metric.  This will be a multiclass classification problem with evenly distributed classes, and so I will use accuracy score and f1 score.  I will use Count Vectorizer to transform the text into a useable form for the algorithms.  I will test using unigrams (words), bigrams (two word combinations), and the combination of the two.  \n",
    "\n",
    "I will test the following classifcation algorithms:\n",
    "- Decision Tree\n",
    "- Random Forest\n",
    "- Logistic Regression \n",
    "- Support Vector Machines \n",
    "- Naive Bayes\n",
    "- k-Nearest Neighbors \n",
    "\n",
    "From there I will tune the most successful algorithms and select the one I will use for my final model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = pd.read_csv('clean_review_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(493265, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>contains interesting stitches</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>fairly experienced knitter onecolor color bloc...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>great book index terrible write high light cro...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>purchased kindle edition incredibly handy part...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>very well laid very easy read book also nice s...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                         reviewText sentiment\n",
       "0           0                      contains interesting stitches  positive\n",
       "1           1  fairly experienced knitter onecolor color bloc...  positive\n",
       "2           2  great book index terrible write high light cro...  positive\n",
       "3           3  purchased kindle edition incredibly handy part...  positive\n",
       "4           4  very well laid very easy read book also nice s...  positive"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>contains interesting stitches</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fairly experienced knitter onecolor color bloc...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>great book index terrible write high light cro...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>purchased kindle edition incredibly handy part...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>very well laid very easy read book also nice s...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493260</th>\n",
       "      <td>not love price watercolor pens not messy score</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493261</th>\n",
       "      <td>lots color markers</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493262</th>\n",
       "      <td>really fun use love watercolor not know made w...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493263</th>\n",
       "      <td>box says vibrant colors only pencils actually ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493264</th>\n",
       "      <td>core very hard not transfer color paper well p...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>493265 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               reviewText sentiment\n",
       "0                           contains interesting stitches  positive\n",
       "1       fairly experienced knitter onecolor color bloc...  positive\n",
       "2       great book index terrible write high light cro...  positive\n",
       "3       purchased kindle edition incredibly handy part...  positive\n",
       "4       very well laid very easy read book also nice s...  positive\n",
       "...                                                   ...       ...\n",
       "493260     not love price watercolor pens not messy score  positive\n",
       "493261                                 lots color markers  positive\n",
       "493262  really fun use love watercolor not know made w...  positive\n",
       "493263  box says vibrant colors only pencils actually ...  negative\n",
       "493264  core very hard not transfer color paper well p...   neutral\n",
       "\n",
       "[493265 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the text into X and the sentiment, the targets, into y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = clean_df['reviewText']\n",
    "y = clean_df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(493265,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the shape \n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(493265,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the shape \n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into Training and Testing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the split I will be heavily downsampling the positive class within the training dataset.  For this reason I am making the training set very small here.  The result will be that the training/testing split will be close to 80/20 once I resample the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, X_test, y_train, y_test) = train_test_split(X, y, test_size=0.05, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train:  (468601,)\n",
      "Shape of X_test:  (24664,)\n",
      "Shape of y_train:  (468601,)\n",
      "Shape of y_test:  (24664,)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of X_train: ',X_train.shape)\n",
    "print('Shape of X_test: ',X_test.shape)\n",
    "print('Shape of y_train: ',y_train.shape)\n",
    "print('Shape of y_test: ',y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert into a dataframe\n",
    "X_train = pd.DataFrame(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the labels back onto the dataframe\n",
    "X_train['label'] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>240017</th>\n",
       "      <td>good</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198869</th>\n",
       "      <td>loved much gave away lol pretty mess experimen...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385992</th>\n",
       "      <td>good</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410577</th>\n",
       "      <td>great colors dual tip get very small places co...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460059</th>\n",
       "      <td>wanted great</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439107</th>\n",
       "      <td>very good product easy use</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117952</th>\n",
       "      <td>good quality easy use spoon</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435829</th>\n",
       "      <td>thanks</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305711</th>\n",
       "      <td>best scissors cut appliqu pieces very comforta...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461484</th>\n",
       "      <td>love set makes flower molding easy look beautiful</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>468601 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               reviewText     label\n",
       "240017                                               good  positive\n",
       "198869  loved much gave away lol pretty mess experimen...  positive\n",
       "385992                                               good  positive\n",
       "410577  great colors dual tip get very small places co...  positive\n",
       "460059                                       wanted great  positive\n",
       "...                                                   ...       ...\n",
       "439107                         very good product easy use  positive\n",
       "117952                        good quality easy use spoon  positive\n",
       "435829                                             thanks  positive\n",
       "305711  best scissors cut appliqu pieces very comforta...  positive\n",
       "461484  love set makes flower molding easy look beautiful  positive\n",
       "\n",
       "[468601 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create three subsets of the dataframe according to the three targets\n",
    "positives = X_train[X_train['label']=='positive']\n",
    "neutrals = X_train[X_train['label']=='neutral']\n",
    "negatives = X_train[X_train['label']=='negative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive reviews: 415680\n",
      "Neutral reviews: 27164\n",
      "Negative reviews: 25757\n"
     ]
    }
   ],
   "source": [
    "# Get the lengths of these \n",
    "print(\"Positive reviews:\", len(positives))\n",
    "print(\"Neutral reviews:\", len(neutrals))\n",
    "print(\"Negative reviews:\", len(negatives))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsampling the Majority Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will make use of Scikit Learn's resample in order to balance the classes in the training data.  I will downsample both the positive and neutral sets so that the counts will correspond with that of the negative class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample the positive class without replacement \n",
    "pos_downsampled = resample(positives,\n",
    "                          replace=False,\n",
    "                          n_samples = len(negatives),\n",
    "                          random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample the neutral class without replacement \n",
    "neu_downsampled = resample(neutrals,\n",
    "                          replace=False,\n",
    "                          n_samples = len(negatives),\n",
    "                          random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the negative class and these two new classes into X_train\n",
    "X_train = pd.concat([pos_downsampled, neu_downsampled, negatives])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    25757\n",
       "negative    25757\n",
       "neutral     25757\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the label counts\n",
    "X_train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>392906</th>\n",
       "      <td>daughter loved set</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313050</th>\n",
       "      <td>really like using stencil texture effects pain...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172906</th>\n",
       "      <td>love mat translucent able use much art project...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342687</th>\n",
       "      <td>nice texture</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371334</th>\n",
       "      <td>very good</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100796</th>\n",
       "      <td>horrible smear constantly even not move paper ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268665</th>\n",
       "      <td>dont let cotton yarn slide</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237824</th>\n",
       "      <td>daughter wanted nylon cord making bracelets no...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211543</th>\n",
       "      <td>not work top mount bobbin even though cut arou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122579</th>\n",
       "      <td>wish would only bought one bought medium large...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77271 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               reviewText     label\n",
       "392906                                 daughter loved set  positive\n",
       "313050  really like using stencil texture effects pain...  positive\n",
       "172906  love mat translucent able use much art project...  positive\n",
       "342687                                       nice texture  positive\n",
       "371334                                          very good  positive\n",
       "...                                                   ...       ...\n",
       "100796  horrible smear constantly even not move paper ...  negative\n",
       "268665                         dont let cotton yarn slide  negative\n",
       "237824  daughter wanted nylon cord making bracelets no...  negative\n",
       "211543  not work top mount bobbin even though cut arou...  negative\n",
       "122579  wish would only bought one bought medium large...  negative\n",
       "\n",
       "[77271 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24664,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the size of the testing dataset \n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that now the training dataset is about three times that of the testing - or about a 75-25 split after the downsampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make y_train the labels and X_train the text once again\n",
    "y_train = X_train['label']\n",
    "X_train = X_train.drop(columns=['label'])\n",
    "X_train = X_train['reviewText']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing an Evaluation Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned, this is a multiclass classification problem now with an even distribution of labels.  For this reason I will use accuracy score (the percentage of labels corectly predicted).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explaining Count Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use the Count Vectorizer to transform the text data into a useable form.  This is fit on the training data and creates a sparse matrix.  The columns of the matrix are the individual unique words that appear in the training dataset.  The rows correspond to the rows of the training data.  Each entry is the number of times that word appears in that row.  Using the Count Vectorizer allows me to do this model testing by unigrams, bigrams, a combination of these, or any other number of lenghts.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Count Vectorizer object\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit on the training data and transform the training and testing data\n",
    "X_train_cv = vectorizer.fit_transform(X_train)\n",
    "X_test_cv = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary length: 39376\n"
     ]
    }
   ],
   "source": [
    "# Print vocabulary length (the number of unique words in the training data)\n",
    "print('Vocabulary length:', len(vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<77271x39376 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1405133 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine the matrix \n",
    "X_train_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 77,271 rows in the training data and 39,376 unique words.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Classification Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned in the introduction I will be testing six models for this classification problem.  These are Decision Trees, Random Forest, Logistic Regression, Support Vector Machines, Naive Bayes, and k-Nearest Neighbours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 1:  Unigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will fit the six models using the just created Count Vectorizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit a decision tree classifier \n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train_cv, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the labels for the training and testing data\n",
    "dt_train_preds = dt.predict(X_train_cv)\n",
    "dt_preds = dt.predict(X_test_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9832278603874675\n",
      "Testing Accuracy: 0.7268488485241648\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy scores \n",
    "dt_train_acc = accuracy_score(y_train, dt_train_preds)\n",
    "dt_test_acc = accuracy_score(y_test, dt_preds)\n",
    "print(\"Training Accuracy:\", dt_train_acc)\n",
    "print(\"Testing Accuracy:\", dt_test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a random forest classifer  \n",
    "rf = RandomForestClassifier(n_estimators = 100)\n",
    "rf.fit(X_train_cv, y_train)\n",
    "\n",
    "# Predict the labels for training and testing data\n",
    "rf_train_preds = rf.predict(X_train_cv)\n",
    "rf_preds = rf.predict(X_test_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9832278603874675\n",
      "Testing Accuracy: 0.7724213428478754\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy scores\n",
    "rf_train_acc = accuracy_score(y_train, rf_train_preds)\n",
    "rf_test_acc = accuracy_score(y_test, rf_preds)\n",
    "print(\"Training Accuracy:\", rf_train_acc)\n",
    "print(\"Testing Accuracy:\", rf_test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.808660428880175\n",
      "Testing Accuracy: 0.832833279273435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mdjm0\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "# Fit a logistic regression classifier \n",
    "lr = LogisticRegression(solver='liblinear')\n",
    "lr.fit(X_train_cv, y_train) \n",
    "\n",
    "# Predict the labels for training and testing data \n",
    "lr_train_preds = lr.predict(X_train_cv)\n",
    "lr_preds = lr.predict(X_test_cv)\n",
    "\n",
    "# Calculate the accuracy scores \n",
    "lr_train_acc = accuracy_score(y_train, lr_train_preds)\n",
    "lr_test_acc = accuracy_score(y_test, lr_preds)\n",
    "print(\"Training Accuracy:\", lr_train_acc)\n",
    "print(\"Testing Accuracy:\", lr_test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.8444176987485602\n",
      "Testing Accuracy: 0.7990593577684074\n"
     ]
    }
   ],
   "source": [
    "# Fit an SVC classifier \n",
    "svc = SVC()\n",
    "svc.fit(X_train_cv, y_train) \n",
    "\n",
    "# Predict the labels for training and testing data \n",
    "svc_train_preds = svc.predict(X_train_cv)\n",
    "svc_preds = svc.predict(X_test_cv)\n",
    "\n",
    "# Calculate the accuracy scores \n",
    "svc_train_acc = accuracy_score(y_train, svc_train_preds)\n",
    "svc_test_acc = accuracy_score(y_test, svc_preds)\n",
    "print(\"Training Accuracy:\", svc_train_acc)\n",
    "print(\"Testing Accuracy:\", svc_test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.7599099273983771\n",
      "Testing Accuracy: 0.7819493999351281\n"
     ]
    }
   ],
   "source": [
    "# Fit a Multinomial Naive Bayes classifier \n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_cv, y_train)\n",
    "\n",
    "# Predict the labels for training and testing data\n",
    "nb_train_preds = nb.predict(X_train_cv)\n",
    "nb_preds = nb.predict(X_test_cv)\n",
    "\n",
    "# Calculate the accuracy scores \n",
    "nb_train_acc = accuracy_score(y_train, nb_train_preds)\n",
    "nb_test_acc = accuracy_score(y_test, nb_preds)\n",
    "print(\"Training Accuracy:\", nb_train_acc)\n",
    "print(\"Testing Accuracy:\", nb_test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.7398765384167411\n",
      "Testing Accuracy: 0.8005595199481025\n"
     ]
    }
   ],
   "source": [
    "# Fit a KNN Classifier \n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train_cv, y_train)\n",
    "\n",
    "# Predict the labels for training and testing data\n",
    "knn_train_preds = knn.predict(X_train_cv)\n",
    "knn_preds = knn.predict(X_test_cv)\n",
    "\n",
    "# Calculate the accuracy scores \n",
    "knn_train_acc = accuracy_score(y_train, knn_train_preds)\n",
    "knn_test_acc = accuracy_score(y_test, knn_preds)\n",
    "print(\"Training Accuracy:\", knn_train_acc)\n",
    "print(\"Testing Accuracy:\", knn_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the training and testing accuracies\n",
    "train_acc = {'DT': dt_train_acc, 'RF': rf_train_acc, 'LR': lr_train_acc, 'SVC': svc_train_acc, \n",
    "             'NB': nb_train_acc, 'KNN': knn_train_acc}\n",
    "test_acc = {'DT': dt_test_acc, 'RF': rf_test_acc, 'LR': lr_test_acc, 'SVC': svc_test_acc, \n",
    "            'NB': nb_test_acc, 'KNN': knn_test_acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training accuracies for each classifier \n",
    "plt.bar(train_acc.keys(), train_acc.values(), color='g')\n",
    "plt.title(\"Training Accuray with Unigrams\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the testing accuracies for each classifier \n",
    "plt.bar(test_acc.keys(), test_acc.values())\n",
    "plt.title(\"Testing Accuracy with Unigrams\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All six models are between 70% and 80% accuracy on the testing data.  Decision Tree and Random Forest perform the best on the training data.  Decision Tree and SVC take significantly longer than the others.  Logistic Regression seems like the best bet in terms of accuracy and speed for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 2: Bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will now re-vectorize the data, this time using bigrams.  I will check the new size of the vocabulary and then fit each of the same six models, checking their accuracies.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the count vectorizer using bigrams\n",
    "vectorizer = CountVectorizer(ngram_range=(2,2))\n",
    "\n",
    "# Vectorization\n",
    "X_train_bcv = vectorizer.fit_transform(X_train)\n",
    "X_test_bcv = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary length: 681378\n"
     ]
    }
   ],
   "source": [
    "# Get the number of unique bigrams\n",
    "print('Vocabulary length:', len(vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<77271x681378 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1545737 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_bcv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 681,378 bigrams in the 77,271 rows of the training dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of the six models\n",
    "models = []\n",
    "\n",
    "models.append(('dt', DecisionTreeClassifier()))\n",
    "models.append(('rf', RandomForestClassifier()))\n",
    "models.append(('lr', LogisticRegression()))\n",
    "models.append(('svc', SVC()))\n",
    "models.append(('nb', MultinomialNB()))\n",
    "models.append(('knn', KNeighborsClassifier()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mdjm0\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Name     Score\n",
      "0   dt  0.791275\n",
      "1   rf  0.824643\n",
      "2   lr  0.843416\n",
      "3  svc  0.834293\n",
      "4   nb  0.656828\n",
      "5  knn  0.773678\n"
     ]
    }
   ],
   "source": [
    "# Fit each of the six models and make the predictions and check the accuracies\n",
    "# Create a list of the scores for plotting\n",
    "names = []\n",
    "scores = []\n",
    "\n",
    "for name, model in models:\n",
    "    model.fit(X_train_bcv, y_train)\n",
    "    y_pred = model.predict(X_test_bcv)\n",
    "    scores.append(accuracy_score(y_test, y_pred))\n",
    "    names.append(name)\n",
    "\n",
    "model_scores = pd.DataFrame({'Name': names, 'Score': scores})\n",
    "print(model_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the accuracies\n",
    "axis = sns.barplot(x = 'Name', y = 'Score', data = model_scores)\n",
    "axis.set(xlabel='Classifier', ylabel='Accuracy')\n",
    "\n",
    "for p in axis.patches:\n",
    "    height = p.get_height()\n",
    "    axis.text(p.get_x() + p.get_width()/2, height + 0.005, '{:1.4f}'.format(height), ha=\"center\") \n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression has performed the best once again and shows a slight improvement after using the bigrams as opposed to the unigrams.  Random Forest and SVC also perform quite well.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this point on I will focus my efforts on Logistic Regression.  Logistic Regression has performed the most accurately so far and was much faster than Random Forest and Support Vector Machines.  To see if I can improve the model I will apply stemming to the text.  This transforms words into roots and will simply the dataset.  After that I will test Logistic Regression once again on bigrams, and then I will use a combination of unigrams and bigrams. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 3:  Adding Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will make use of NLTK's Snowball Stemmer for this.  Stemming will convert plurals to their singulars and generally reduce all words into shorter forms.\n",
    "\n",
    "(https://www.nltk.org/howto/stem.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_text(input):\n",
    "    # Create a stemmer object\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    \n",
    "    #Split the text and use the stemmer on each word \n",
    "    text = input.split()\n",
    "    words = \"\"\n",
    "    for i in text:\n",
    "        words += (stemmer.stem(i))+' '\n",
    "    \n",
    "    # Return the recombined text\n",
    "    return words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'contains interesting stitches'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print a review to test\n",
    "clean_df['reviewText'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'contain interest stitch '"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the result after stemming\n",
    "stem_text(clean_df['reviewText'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the stem_text function on the training data \n",
    "X_train2 = X_train.apply(stem_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the stem_text function on the testing data\n",
    "X_test2 = X_test.apply(stem_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression with Bigrams and Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(2,2))\n",
    "\n",
    "# Vectorization\n",
    "X_train_bcv2 = vectorizer.fit_transform(X_train2)\n",
    "X_test_bcv2 = vectorizer.transform(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9498000543541562\n",
      "Testing Accuracy: 0.8508757703535518\n"
     ]
    }
   ],
   "source": [
    "# Fit a logistic regression classifier \n",
    "lr = LogisticRegression(solver='liblinear')\n",
    "lr.fit(X_train_bcv2, y_train) \n",
    "\n",
    "# Predict the labels for training and testing data \n",
    "lr_train_preds = lr.predict(X_train_bcv2)\n",
    "lr_preds = lr.predict(X_test_bcv2)\n",
    "\n",
    "# Calculate the accuracy scores \n",
    "lr_train_acc = accuracy_score(y_train, lr_train_preds)\n",
    "lr_test_acc = accuracy_score(y_test, lr_preds)\n",
    "print(\"Training Accuracy:\", lr_train_acc)\n",
    "print(\"Testing Accuracy:\", lr_test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming improves the test accuracy from about 84% to 85%.  Next I will fit a Count Vectorizer that will use both unigrams and bigrams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 4:  Unigrams and Bigrams with Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1,2))\n",
    "\n",
    "# Vectorization\n",
    "X_train_bcv3 = vectorizer.fit_transform(X_train2)\n",
    "X_test_bcv3 = vectorizer.transform(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary length: 584152\n"
     ]
    }
   ],
   "source": [
    "# Get the length of the vocabulary\n",
    "print('Vocabulary length:', len(vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<77271x554885 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1540296 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_bcv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a total of 554,885 unique unigrams and bigrams after the stemming process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9635309495153421\n",
      "Testing Accuracy: 0.8577278624716186\n"
     ]
    }
   ],
   "source": [
    "# Fit a logistic regression classifier \n",
    "lr = LogisticRegression(solver='liblinear')\n",
    "lr.fit(X_train_bcv3, y_train) \n",
    "\n",
    "# Predict the labels for training and testing data \n",
    "lr_train_preds = lr.predict(X_train_bcv3)\n",
    "lr_preds = lr.predict(X_test_bcv3)\n",
    "\n",
    "# Calculate the accuracy scores \n",
    "lr_train_acc = accuracy_score(y_train, lr_train_preds)\n",
    "lr_test_acc = accuracy_score(y_test, lr_preds)\n",
    "print(\"Training Accuracy:\", lr_train_acc)\n",
    "print(\"Testing Accuracy:\", lr_test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again the accuracy is slightly improved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approach 5:  Unigrams, Bigrams and Trigrams with Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1,3))\n",
    "\n",
    "# Vectorization\n",
    "X_train_bcv4 = vectorizer.fit_transform(X_train2)\n",
    "X_test_bcv4 = vectorizer.transform(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary length: 1753074\n"
     ]
    }
   ],
   "source": [
    "print('Vocabulary length:', len(vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this approach we now have a much larger vocabulary - 1,753,074 unique entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.974078244101927\n",
      "Testing Accuracy: 0.8607281868310087\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(solver='liblinear')\n",
    "lr.fit(X_train_bcv4, y_train) \n",
    "lr_train_preds = lr.predict(X_train_bcv4)\n",
    "lr_preds = lr.predict(X_test_bcv4)\n",
    "lr_train_acc = accuracy_score(y_train, lr_train_preds)\n",
    "lr_test_acc = accuracy_score(y_test, lr_preds)\n",
    "print(\"Training Accuracy:\", lr_train_acc)\n",
    "print(\"Testing Accuracy:\", lr_test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again the accuracy for training and testing are both slightly imporved.  I will continue with this model and see if I can improve the accuracy through hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Liblinear Solver and One vs Rest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a multiclass problem such as this, the One vs Rest fits a binary classifier to each of the three labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.974078244101927\n",
      "Testing Accuracy: 0.8607281868310087\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(solver='liblinear', multi_class='ovr')\n",
    "lr.fit(X_train_bcv4, y_train) \n",
    "lr_train_preds = lr.predict(X_train_bcv4)\n",
    "lr_preds = lr.predict(X_test_bcv4)\n",
    "lr_train_acc = accuracy_score(y_train, lr_train_preds)\n",
    "lr_test_acc = accuracy_score(y_test, lr_preds)\n",
    "print(\"Training Accuracy:\", lr_train_acc)\n",
    "print(\"Testing Accuracy:\", lr_test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Newton-CG Solver and Multinomial "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The multinomial parameter minimizes the multinomial loss across all data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9778312691695461\n",
      "Testing Accuracy: 0.8516866688290626\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(solver='newton-cg', multi_class='multinomial')\n",
    "lr.fit(X_train_bcv4, y_train) \n",
    "lr_train_preds = lr.predict(X_train_bcv4)\n",
    "lr_preds = lr.predict(X_test_bcv4)\n",
    "lr_train_acc = accuracy_score(y_train, lr_train_preds)\n",
    "lr_test_acc = accuracy_score(y_test, lr_preds)\n",
    "print(\"Training Accuracy:\", lr_train_acc)\n",
    "print(\"Testing Accuracy:\", lr_test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Newton-CG Solver and One vs Rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9498000543541562\n",
      "Testing Accuracy: 0.8508757703535518\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(solver='newton-cg', multi_class='ovr')\n",
    "lr.fit(X_train_bcv2, y_train) \n",
    "lr_train_preds = lr.predict(X_train_bcv2)\n",
    "lr_preds = lr.predict(X_test_bcv2)\n",
    "lr_train_acc = accuracy_score(y_train, lr_train_preds)\n",
    "lr_test_acc = accuracy_score(y_test, lr_preds)\n",
    "print(\"Training Accuracy:\", lr_train_acc)\n",
    "print(\"Testing Accuracy:\", lr_test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lowering the C-value "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lowered C-value (the default is 1) increases regularization and reduces overfitting on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.932031421878842\n",
      "Testing Accuracy: 0.8542409990269219\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(solver='liblinear', multi_class='ovr', C = 0.50)\n",
    "lr.fit(X_train_bcv2, y_train) \n",
    "lr_train_preds = lr.predict(X_train_bcv2)\n",
    "lr_preds = lr.predict(X_test_bcv2)\n",
    "lr_train_acc = accuracy_score(y_train, lr_train_preds)\n",
    "lr_test_acc = accuracy_score(y_test, lr_preds)\n",
    "print(\"Training Accuracy:\", lr_train_acc)\n",
    "print(\"Testing Accuracy:\", lr_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.8560261935266789\n",
      "Testing Accuracy: 0.8589847551086603\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(solver='liblinear', multi_class='ovr', C = 0.1)\n",
    "lr.fit(X_train_bcv2, y_train) \n",
    "lr_train_preds = lr.predict(X_train_bcv2)\n",
    "lr_preds = lr.predict(X_test_bcv2)\n",
    "lr_train_acc = accuracy_score(y_train, lr_train_preds)\n",
    "lr_test_acc = accuracy_score(y_test, lr_preds)\n",
    "print(\"Training Accuracy:\", lr_train_acc)\n",
    "print(\"Testing Accuracy:\", lr_test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best result obtained is with the liblinear solver and the One vs Rest multiclass parameter.  This will be the model used in the next notebook to extract labels for new text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining the Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.974078244101927\n",
      "Testing Accuracy: 0.8607281868310087\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(solver='liblinear', multi_class='ovr')\n",
    "lr.fit(X_train_bcv4, y_train) \n",
    "lr_train_preds = lr.predict(X_train_bcv4)\n",
    "lr_preds = lr.predict(X_test_bcv4)\n",
    "lr_train_acc = accuracy_score(y_train, lr_train_preds)\n",
    "lr_test_acc = accuracy_score(y_test, lr_preds)\n",
    "print(\"Training Accuracy:\", lr_train_acc)\n",
    "print(\"Testing Accuracy:\", lr_test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, check the classification report to see how the model is performing on each of the three classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.54      0.79      0.64      1373\n",
      "     neutral       0.30      0.66      0.41      1440\n",
      "    positive       0.99      0.88      0.93     21851\n",
      "\n",
      "    accuracy                           0.86     24664\n",
      "   macro avg       0.61      0.78      0.66     24664\n",
      "weighted avg       0.92      0.86      0.88     24664\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, lr_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the model performs the best on the positive class and worst on the neutral class.  Next I will examine the coefficients of the Logistic Regression model in order to generate a list of the most important words and phrases it has attributed to each of the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive'], dtype=object)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making a checking a prediction\n",
    "lr.predict(X_test_bcv4[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence in Negative Label: 0.0004512520091981016\n",
      "Confidence in Neutral Label: 0.024424583762959286\n",
      "Confidence in Positive Label: 0.9751241642278425\n"
     ]
    }
   ],
   "source": [
    "# Using Predict_proba to generate the probabilities attributed to each class label\n",
    "confidence = lr.predict_proba(X_test_bcv4[0])\n",
    "print('Confidence in Negative Label:', confidence[0][0])\n",
    "print('Confidence in Neutral Label:', confidence[0][1])\n",
    "print('Confidence in Positive Label:', confidence[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the correct label\n",
    "y_test.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining the Logistic Regression Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1753074"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The number of features\n",
    "len(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1753074)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The number of coefficients \n",
    "lr.coef_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['negative', 'neutral', 'positive'], dtype=object)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The classes \n",
    "lr.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the three classes I will extract the coefficients of the logistic regression model for each of the features in the vectorizer.  I will then sort the coefficients and print the five that have the highest values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Negative Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_to_coef = {\n",
    "    word: coef for word, coef in zip(\n",
    "        vectorizer.get_feature_names(), lr.coef_[0])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('junk', 3.0726358223736043)\n",
      "('useless', 2.7383975515160652)\n",
      "('no good', 2.5882426497003044)\n",
      "('horribl', 2.5234650915169516)\n",
      "('terribl', 2.3688897595392047)\n"
     ]
    }
   ],
   "source": [
    "# Sort the created dictionary according to value and print the five largest\n",
    "for most_important_negative in sorted(feature_to_coef.items(), key=lambda x: x[1], reverse=True)[:5]:\n",
    "    print (most_important_negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the most important negative phrases for the model, and these clearly represent a strongly negative sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Neutral Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_to_coef = {\n",
    "    word: coef for word, coef in zip(\n",
    "        vectorizer.get_feature_names(), lr.coef_[1])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('three star', 4.0288150141789885)\n",
      "('okay', 2.350508982553373)\n",
      "('ok', 2.1440595823248274)\n",
      "('averag', 2.0967954420772332)\n",
      "('not bad', 2.0171706545013692)\n"
     ]
    }
   ],
   "source": [
    "for most_important_neutral in sorted(feature_to_coef.items(), key=lambda x: x[1], reverse=True)[:5]:\n",
    "    print (most_important_neutral)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are what you would expect out of a neutral sentiment.  \"Average\", \"okay\", \"not bad\", \"three stars\".  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Positive Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_to_coef = {\n",
    "    word: coef for word, coef in zip(\n",
    "        vectorizer.get_feature_names(), lr.coef_[2])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('awesom', 3.0363366564732814)\n",
      "('perfect', 3.0031275090763097)\n",
      "('love', 2.8913258130581916)\n",
      "('excel', 2.8235221812581006)\n",
      "('never disappoint', 2.524678366389776)\n"
     ]
    }
   ],
   "source": [
    "for most_important_positive in sorted(feature_to_coef.items(), key=lambda x: x[1], reverse=True)[:5]:\n",
    "    print (most_important_positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally for positive, these words and phrases summarize a high rating and a positive sentiment.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Split, Resampled, and Stemmed Data for the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2.to_csv('clean_training_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test2.to_csv('clean_testing_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.to_csv('training_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.to_csv('testing_labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next notebook will build a pipeline to use all of the text cleaning functions to transform a user's English text into a form that is suitable for the model.  I will then use the model created here to generate the sentiment for the new text.  I will use this examination of the coefficients to produce a list of the most important words or phrases that model found in the input text in reaching its label determination. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
